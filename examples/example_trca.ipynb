{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Task-related component analysis (TRCA)-based SSVEP detection\n",
        "\n",
        "Sample code for the task-related component analysis (TRCA)-based steady\n",
        "-state visual evoked potential (SSVEP) detection method [1]_. The filter\n",
        "bank analysis can also be combined to the TRCA-based algorithm [2]_ [3]_.\n",
        "\n",
        "This code is based on the Matlab implementation from:\n",
        "https://github.com/mnakanishi/TRCA-SSVEP\n",
        "\n",
        "Uses `meegkit.trca.TRCA()`.\n",
        "\n",
        "References:\n",
        "\n",
        ".. [1] M. Nakanishi, Y. Wang, X. Chen, Y.-T. Wang, X. Gao, and T.-P. Jung,\n",
        "   \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
        "   task-related component analysis\", IEEE Trans. Biomed. Eng, 65(1): 104-112,\n",
        "   2018.\n",
        "\n",
        ".. [2] X. Chen, Y. Wang, S. Gao, T. -P. Jung and X. Gao, \"Filter bank\n",
        "   canonical correlation analysis for implementing a high-speed SSVEP-based\n",
        "   brain-computer interface\", J. Neural Eng., 12: 046008, 2015.\n",
        "   \n",
        ".. [3] X. Chen, Y. Wang, M. Nakanishi, X. Gao, T. -P. Jung, S. Gao,\n",
        "   \"High-speed spelling with a noninvasive brain-computer interface\",\n",
        "   Proc. Int. Natl. Acad. Sci. U. S. A, 112(44): E6058-6067, 2015.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Giuseppe Ferraro <giuseppe.ferraro@isae-supaero.fr>\n",
        "#          Nicolas Barascud <nicolas.barascud@gmail.com>\n",
        "import os\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from meegkit.trca import TRCA\n",
        "from meegkit.utils.trca import itr, normfit, round_half_up\n",
        "\n",
        "t = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dur_gaze = 0.5  # data length for target identification [s]\n",
        "delay = 0.13  # visual latency being considered in the analysis [s]\n",
        "n_bands = 5  # number of sub-bands in filter bank analysis\n",
        "is_ensemble = True  # True = ensemble TRCA method; False = TRCA method\n",
        "alpha_ci = 0.05   # 100*(1-alpha_ci): confidence interval for accuracy\n",
        "sfreq = 250  # sampling rate [Hz]\n",
        "dur_shift = 0.5  # duration for gaze shifting [s]\n",
        "list_freqs = np.array(\n",
        "    [[x + 8.0 for x in range(8)],\n",
        "     [x + 8.2 for x in range(8)],\n",
        "     [x + 8.4 for x in range(8)],\n",
        "     [x + 8.6 for x in range(8)],\n",
        "     [x + 8.8 for x in range(8)]]).T  # list of stimulus frequencies\n",
        "n_targets = list_freqs.size  # The number of stimuli\n",
        "\n",
        "# Useful variables (no need to modify)\n",
        "dur_gaze_s = round_half_up(dur_gaze * sfreq)  # data length [samples]\n",
        "delay_s = round_half_up(delay * sfreq)  # visual latency [samples]\n",
        "dur_sel_s = dur_gaze + dur_shift  # selection time [s]\n",
        "ci = 100 * (1 - alpha_ci)  # confidence interval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = os.path.join('..', 'tests', 'data', 'trcadata.mat')\n",
        "eeg = scipy.io.loadmat(path)[\"eeg\"]\n",
        "\n",
        "n_trials, n_chans, n_samples, n_blocks = eeg.shape\n",
        "\n",
        "# Convert dummy Matlab format to (sample, channels, trials) and construct\n",
        "# vector of labels\n",
        "eeg = np.reshape(eeg.transpose([2, 1, 3, 0]),\n",
        "                 (n_samples, n_chans, n_trials * n_blocks))\n",
        "labels = np.array([x for x in range(n_targets)] * n_blocks)\n",
        "crop_data = np.arange(delay_s, delay_s + dur_gaze_s)\n",
        "eeg = eeg[crop_data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TRCA classification\n",
        "Estimate classification performance with a Leave-One-Block-Out\n",
        "cross-validation approach.\n",
        "\n",
        "To get a sense of the filterbank specification in relation to the stimuli\n",
        "we can plot the individual filterbank sub-bands as well as the target\n",
        "frequencies (with their expected harmonics in the EEG spectrum). We use the\n",
        "filterbank specification described in [2]_.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filterbank = [[(6, 90), (4, 100)],  # passband, stopband freqs [(Wp), (Ws)]\n",
        "              [(14, 90), (10, 100)],\n",
        "              [(22, 90), (16, 100)],\n",
        "              [(30, 90), (24, 100)],\n",
        "              [(38, 90), (32, 100)],\n",
        "              [(46, 90), (40, 100)],\n",
        "              [(54, 90), (48, 100)]]\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(7, 4))\n",
        "for i, band in enumerate(filterbank):\n",
        "    ax.axvspan(ymin=i / len(filterbank) + .02,\n",
        "               ymax=(i + 1) / len(filterbank) - .02,\n",
        "               xmin=filterbank[i][1][0], xmax=filterbank[i][1][1],\n",
        "               alpha=0.2, facecolor=f'C{i}')\n",
        "    ax.axvspan(ymin=i / len(filterbank) + .02,\n",
        "               ymax=(i + 1) / len(filterbank) - .02,\n",
        "               xmin=filterbank[i][0][0], xmax=filterbank[i][0][1],\n",
        "               alpha=0.5, label=f'sub-band{i}', facecolor=f'C{i}')\n",
        "\n",
        "for f in list_freqs.flat:\n",
        "    colors = np.ones((9, 4))\n",
        "    colors[:, :3] = np.linspace(0, .5, 9)[:, None]\n",
        "    ax.scatter(f * np.arange(1, 10), [f] * 9, c=colors, s=8, zorder=100)\n",
        "\n",
        "ax.set_ylabel('Stimulus frequency (Hz)')\n",
        "ax.set_xlabel('EEG response frequency (Hz)')\n",
        "ax.set_xlim([0, 102])\n",
        "ax.set_xticks(np.arange(0, 100, 10))\n",
        "ax.grid(True, ls=':', axis='x')\n",
        "ax.legend(bbox_to_anchor=(1.05, .5), fontsize='small')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now perform the TRCA-based SSVEP detection algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trca = TRCA(sfreq, filterbank, is_ensemble)\n",
        "\n",
        "print('Results of the ensemble TRCA-based method:\\n')\n",
        "accs = np.zeros(n_blocks)\n",
        "itrs = np.zeros(n_blocks)\n",
        "for i in range(n_blocks):\n",
        "\n",
        "    # Select all folds except one for training\n",
        "    traindata = np.concatenate(\n",
        "        (eeg[..., :i * n_trials],\n",
        "         eeg[..., (i + 1) * n_trials:]), 2)\n",
        "    y_train = np.concatenate(\n",
        "        (labels[:i * n_trials], labels[(i + 1) * n_trials:]), 0)\n",
        "\n",
        "    # Construction of the spatial filter and the reference signals\n",
        "    trca.fit(traindata, y_train)\n",
        "\n",
        "    # Test stage\n",
        "    testdata = eeg[..., i * n_trials:(i + 1) * n_trials]\n",
        "    y_test = labels[i * n_trials:(i + 1) * n_trials]\n",
        "    estimated = trca.predict(testdata)\n",
        "\n",
        "    # Evaluation of the performance for this fold (accuracy and ITR)\n",
        "    is_correct = estimated == y_test\n",
        "    accs[i] = np.mean(is_correct) * 100\n",
        "    itrs[i] = itr(n_targets, np.mean(is_correct), dur_sel_s)\n",
        "    print(f\"Block {i}: accuracy = {accs[i]:.1f}, \\tITR = {itrs[i]:.1f}\")\n",
        "\n",
        "# Mean accuracy and ITR computation\n",
        "mu, _, muci, _ = normfit(accs, alpha_ci)\n",
        "print(f\"\\nMean accuracy = {mu:.1f}%\\t({ci:.0f}% CI: {muci[0]:.1f}-{muci[1]:.1f}%)\")  # noqa\n",
        "\n",
        "mu, _, muci, _ = normfit(itrs, alpha_ci)\n",
        "print(f\"Mean ITR = {mu:.1f}\\t({ci:.0f}% CI: {muci[0]:.1f}-{muci[1]:.1f})\")\n",
        "if is_ensemble:\n",
        "    ensemble = 'ensemble TRCA-based method'\n",
        "else:\n",
        "    ensemble = 'TRCA-based method'\n",
        "\n",
        "print(f\"\\nElapsed time: {time.time()-t:.1f} seconds\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}