{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Task-related component analysis for SSVEP detection\n\nSample code for the task-related component analysis (TRCA)-based steady\n-state visual evoked potential (SSVEP) detection method [1]_. The filter\nbank analysis can also be combined to the TRCA-based algorithm [2]_ [3]_.\n\nThis code is based on the Matlab implementation from:\nhttps://github.com/mnakanishi/TRCA-SSVEP\n\nUses `meegkit.trca.TRCA()`.\n\n## References\n.. [1] M. Nakanishi, Y. Wang, X. Chen, Y.-T. Wang, X. Gao, and T.-P. Jung,\n   \"Enhancing detection of SSVEPs for a high-speed brain speller using\n   task-related component analysis\", IEEE Trans. Biomed. Eng, 65(1): 104-112,\n   2018.\n.. [2] X. Chen, Y. Wang, S. Gao, T. -P. Jung and X. Gao, \"Filter bank\n   canonical correlation analysis for implementing a high-speed SSVEP-based\n   brain-computer interface\", J. Neural Eng., 12: 046008, 2015.\n.. [3] X. Chen, Y. Wang, M. Nakanishi, X. Gao, T. -P. Jung, S. Gao,\n   \"High-speed spelling with a noninvasive brain-computer interface\",\n   Proc. Int. Natl. Acad. Sci. U. S. A, 112(44): E6058-6067, 2015.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Giuseppe Ferraro <giuseppe.ferraro@isae-supaero.fr>\n#          Nicolas Barascud <nicolas.barascud@gmail.com>\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.io\n\nfrom meegkit.trca import TRCA\nfrom meegkit.utils.trca import itr, normfit, round_half_up\n\nt = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dur_gaze = 0.5  # data length for target identification [s]\ndelay = 0.13  # visual latency being considered in the analysis [s]\nn_bands = 5  # number of sub-bands in filter bank analysis\nis_ensemble = True  # True = ensemble TRCA method; False = TRCA method\nalpha_ci = 0.05   # 100*(1-alpha_ci): confidence interval for accuracy\nsfreq = 250  # sampling rate [Hz]\ndur_shift = 0.5  # duration for gaze shifting [s]\nlist_freqs = np.array(\n    [[x + 8.0 for x in range(8)],\n     [x + 8.2 for x in range(8)],\n     [x + 8.4 for x in range(8)],\n     [x + 8.6 for x in range(8)],\n     [x + 8.8 for x in range(8)]]).T  # list of stimulus frequencies\nn_targets = list_freqs.size  # The number of stimuli\n\n# Useful variables (no need to modify)\ndur_gaze_s = round_half_up(dur_gaze * sfreq)  # data length [samples]\ndelay_s = round_half_up(delay * sfreq)  # visual latency [samples]\ndur_sel_s = dur_gaze + dur_shift  # selection time [s]\nci = 100 * (1 - alpha_ci)  # confidence interval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = os.path.join(\"..\", \"tests\", \"data\", \"trcadata.mat\")\neeg = scipy.io.loadmat(path)[\"eeg\"]\n\nn_trials, n_chans, n_samples, n_blocks = eeg.shape\n\n# Convert dummy Matlab format to (sample, channels, trials) and construct\n# vector of labels\neeg = np.reshape(eeg.transpose([2, 1, 3, 0]),\n                 (n_samples, n_chans, n_trials * n_blocks))\nlabels = np.array([x for x in range(n_targets)] * n_blocks)\ncrop_data = np.arange(delay_s, delay_s + dur_gaze_s)\neeg = eeg[crop_data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TRCA classification\nEstimate classification performance with a Leave-One-Block-Out\ncross-validation approach.\n\nTo get a sense of the filterbank specification in relation to the stimuli\nwe can plot the individual filterbank sub-bands as well as the target\nfrequencies (with their expected harmonics in the EEG spectrum). We use the\nfilterbank specification described in [2]_.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filterbank = [[(6, 90), (4, 100)],  # passband, stopband freqs [(Wp), (Ws)]\n              [(14, 90), (10, 100)],\n              [(22, 90), (16, 100)],\n              [(30, 90), (24, 100)],\n              [(38, 90), (32, 100)],\n              [(46, 90), (40, 100)],\n              [(54, 90), (48, 100)]]\n\nf, ax = plt.subplots(1, figsize=(7, 4))\nfor i, _band in enumerate(filterbank):\n    ax.axvspan(ymin=i / len(filterbank) + .02,\n               ymax=(i + 1) / len(filterbank) - .02,\n               xmin=filterbank[i][1][0], xmax=filterbank[i][1][1],\n               alpha=0.2, facecolor=f\"C{i}\")\n    ax.axvspan(ymin=i / len(filterbank) + .02,\n               ymax=(i + 1) / len(filterbank) - .02,\n               xmin=filterbank[i][0][0], xmax=filterbank[i][0][1],\n               alpha=0.5, label=f\"sub-band{i}\", facecolor=f\"C{i}\")\n\nfor f in list_freqs.flat:\n    colors = np.ones((9, 4))\n    colors[:, :3] = np.linspace(0, .5, 9)[:, None]\n    ax.scatter(f * np.arange(1, 10), [f] * 9, c=colors, s=8, zorder=100)\n\nax.set_ylabel(\"Stimulus frequency (Hz)\")\nax.set_xlabel(\"EEG response frequency (Hz)\")\nax.set_xlim([0, 102])\nax.set_xticks(np.arange(0, 100, 10))\nax.grid(True, ls=\":\", axis=\"x\")\nax.legend(bbox_to_anchor=(1.05, .5), fontsize=\"small\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now perform the TRCA-based SSVEP detection algorithm\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trca = TRCA(sfreq, filterbank, is_ensemble)\n\nprint(\"Results of the ensemble TRCA-based method:\\n\")\naccs = np.zeros(n_blocks)\nitrs = np.zeros(n_blocks)\nfor i in range(n_blocks):\n\n    # Select all folds except one for training\n    traindata = np.concatenate(\n        (eeg[..., :i * n_trials],\n         eeg[..., (i + 1) * n_trials:]), 2)\n    y_train = np.concatenate(\n        (labels[:i * n_trials], labels[(i + 1) * n_trials:]), 0)\n\n    # Construction of the spatial filter and the reference signals\n    trca.fit(traindata, y_train)\n\n    # Test stage\n    testdata = eeg[..., i * n_trials:(i + 1) * n_trials]\n    y_test = labels[i * n_trials:(i + 1) * n_trials]\n    estimated = trca.predict(testdata)\n\n    # Evaluation of the performance for this fold (accuracy and ITR)\n    is_correct = estimated == y_test\n    accs[i] = np.mean(is_correct) * 100\n    itrs[i] = itr(n_targets, np.mean(is_correct), dur_sel_s)\n    print(f\"Block {i}: accuracy = {accs[i]:.1f}, \\tITR = {itrs[i]:.1f}\")\n\n# Mean accuracy and ITR computation\nmu, _, muci, _ = normfit(accs, alpha_ci)\nprint(f\"\\nMean accuracy = {mu:.1f}%\\t({ci:.0f}% CI: {muci[0]:.1f}-{muci[1]:.1f}%)\")  # noqa\n\nmu, _, muci, _ = normfit(itrs, alpha_ci)\nprint(f\"Mean ITR = {mu:.1f}\\t({ci:.0f}% CI: {muci[0]:.1f}-{muci[1]:.1f})\")\nif is_ensemble:\n    ensemble = \"ensemble TRCA-based method\"\nelse:\n    ensemble = \"TRCA-based method\"\n\nprint(f\"\\nElapsed time: {time.time()-t:.1f} seconds\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}